import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
import streamlit as st
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score

# ---------------------------
# Streamlit App
# ---------------------------
st.title("ðŸ“ˆ SPY Tomorrow Predictor")
st.write("Logistic Regression models on SPY data (10 years).")

# Step 1: Data Collection
spy = yf.Ticker("SPY")
data = spy.history(period="3y")

# data.columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']
dataset = data[['Open', 'High', 'Low', 'Close', 'Volume']]

# Step 2: Feature Engineering
dataset['short_mavg'] = dataset['Close'].rolling(window=10, min_periods=1).mean()
dataset['long_mavg'] = dataset['Close'].rolling(window=60, min_periods=1).mean()

# Target variables
dataset['Sign_1'] = np.where(dataset['short_mavg'] > dataset['long_mavg'], 1.0, 0.0)
dataset['Sign_1'] = dataset['Sign_1'].shift(-10)
dataset['Sign_2'] = (np.sign(np.log(dataset['Close'] / dataset['Close'].shift(1))) > 0).astype(int)
dataset['Sign_2'] = dataset['Sign_2'].shift(-1)

# Additional features
dataset['O-C'] = dataset['Close'] - dataset['Open']
dataset['H-L'] = dataset['High'] - dataset['Low']
dataset['Log_Return'] = np.log(dataset['Close'] / dataset['Close'].shift(1))
dataset['Momentum'] = dataset['Close'].diff(1)
dataset['SMA_5'] = dataset['Close'].rolling(window=5).mean()
dataset['SMA_10'] = dataset['Close'].rolling(window=10).mean()
dataset['SMA_20'] = dataset['Close'].rolling(window=20).mean()
dataset['SMA_50'] = dataset['Close'].rolling(window=50).mean()
dataset['SMA_100'] = dataset['Close'].rolling(window=100).mean()
dataset['EMA_5'] = dataset['Close'].ewm(span=5, adjust=False).mean()
dataset['EMA_10'] = dataset['Close'].ewm(span=10, adjust=False).mean()
dataset['EMA_20'] = dataset['Close'].ewm(span=20, adjust=False).mean()
dataset['EMA_50'] = dataset['Close'].ewm(span=50, adjust=False).mean()
dataset['EMA_100'] = dataset['Close'].ewm(span=100, adjust=False).mean()

# RSI
delta = dataset['Close'].diff(1)
gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
rs = gain / loss
dataset['RSI'] = 100 - (100 / (1 + rs))

dataset.dropna(inplace=True)

# Step 3: Train / Validation Split
validation_size = 0.2
split_index = int(len(dataset) * (1 - validation_size))
train_df = dataset.iloc[:split_index]
validation_df = dataset.iloc[split_index:]

features = [
    'O-C', 'H-L', 'Log_Return', 'Momentum',
    'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'SMA_100',
    'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'EMA_100',
    'RSI'
]

X_train = train_df[features]
Y_train_1 = train_df['Sign_1']
Y_train_2 = train_df['Sign_2']

X_validation = validation_df[features]
Y_validation_1 = validation_df['Sign_1']
Y_validation_2 = validation_df['Sign_2']

# Scale
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_validation_scaled = scaler.transform(X_validation)

# Step 4: Train Models
model1 = LogisticRegression(solver='liblinear')
model1.fit(X_train_scaled, Y_train_1)

model2 = LogisticRegression(solver='liblinear')
model2.fit(X_train_scaled, Y_train_2)

# Step 5: Validation Scores
predictions1 = model1.predict(X_validation_scaled)
predictions2 = model2.predict(X_validation_scaled)

acc1 = accuracy_score(Y_validation_1, predictions1)
acc2 = accuracy_score(Y_validation_2, predictions2)

st.subheader("ðŸ“Š Model Accuracy")
st.write(f"Model 1 (MA crossover): **{acc1:.2%}**")
st.write(f"Model 2 (Daily returns): **{acc2:.2%}**")

# Step 6: Predict Tomorrow
latest_features = dataset[features].iloc[-1:].copy()
latest_scaled = scaler.transform(latest_features)

# Predictions & probabilities
tomorrow_pred1 = model1.predict(latest_scaled)[0]
tomorrow_prob1 = model1.predict_proba(latest_scaled)[0][1]

tomorrow_pred2 = model2.predict(latest_scaled)[0]
tomorrow_prob2 = model2.predict_proba(latest_scaled)[0][1]

signal_map = {0: "DOWN", 1: "UP"}

st.subheader("ðŸ”® Tomorrow's Prediction")
st.write(f"Model 1 (MA Crossover): **{signal_map[tomorrow_pred1]}** (prob={tomorrow_prob1:.2f})")
st.write(f"Model 2 (Daily Returns): **{signal_map[tomorrow_pred2]}** (prob={tomorrow_prob2:.2f})")

# Step 7: Consensus Signal
votes = [tomorrow_pred1, tomorrow_pred2]
vote_sum = sum(votes)

if vote_sum == 2:
    final_signal = "UP âœ…"
elif vote_sum == 0:
    final_signal = "DOWN â¬‡ï¸"
else:
    final_signal = "NEUTRAL âš–ï¸"

st.subheader("ðŸ“Œ Final Consensus Signal")
st.write(f"**{final_signal}**")

# Step 8: Validation Backtest Chart with Signals
st.subheader("ðŸ“‰ SPY Backtest with Signals")

# Consensus for validation
consensus = []
for p1, p2 in zip(predictions1, predictions2):
    if p1 + p2 == 2:
        consensus.append(1)
    elif p1 + p2 == 0:
        consensus.append(0)
    else:
        consensus.append(np.nan)  # Neutral

validation_df = validation_df.copy()
validation_df['Consensus'] = consensus
validation_df['Market Returns'] = validation_df['Close'].pct_change()
validation_df['Strategy Returns'] = validation_df['Market Returns'] * validation_df['Consensus'].shift(1)

# Plot signals on price
fig, ax = plt.subplots(figsize=(10, 5))
ax.plot(validation_df.index, validation_df['Close'], label='SPY Close', color='blue')

ax.scatter(validation_df.index[validation_df['Consensus'] == 1],
           validation_df['Close'][validation_df['Consensus'] == 1],
           marker='^', color='green', label='Buy Signal', alpha=0.8)

ax.scatter(validation_df.index[validation_df['Consensus'] == 0],
           validation_df['Close'][validation_df['Consensus'] == 0],
           marker='v', color='red', label='Sell Signal', alpha=0.8)

ax.set_title("SPY Validation Period with Consensus Buy/Sell Signals")
ax.set_xlabel("Date")
ax.set_ylabel("Price")
ax.legend()
st.pyplot(fig)

# Step 9: Backtest Performance
st.subheader("ðŸ“ˆ Backtest Performance")

validation_df['Cumulative BuyHold'] = (1 + validation_df['Market Returns']).cumprod()
validation_df['Cumulative Strategy'] = (1 + validation_df['Strategy Returns'].fillna(0)).cumprod()

fig2, ax2 = plt.subplots(figsize=(10, 5))
ax2.plot(validation_df.index, validation_df['Cumulative BuyHold'], label="Buy & Hold", color='black')
ax2.plot(validation_df.index, validation_df['Cumulative Strategy'], label="Consensus Strategy", color='orange')
ax2.set_title("Cumulative Returns: Consensus vs Buy & Hold")
ax2.set_xlabel("Date")
ax2.set_ylabel("Cumulative Growth")
ax2.legend()
st.pyplot(fig2)

st.write("Final Returns:")
st.write(f"Buy & Hold: **{validation_df['Cumulative BuyHold'].iloc[-1]-1:.2%}**")
st.write(f"Consensus Strategy: **{validation_df['Cumulative Strategy'].iloc[-1]-1:.2%}**")

# Optional: ROC curve for Model 1
st.subheader("ðŸ“ ROC Curve (Model 1)")
y_pred_prob = model1.predict_proba(X_validation_scaled)[:, 1]
fpr, tpr, _ = roc_curve(Y_validation_1, y_pred_prob)
roc_auc = roc_auc_score(Y_validation_1, y_pred_prob)

fig3, ax3 = plt.subplots()
ax3.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
ax3.plot([0, 1], [0, 1], 'k--')
ax3.set_xlim([0.0, 1.0])
ax3.set_ylim([0.0, 1.05])
ax3.set_xlabel('False Positive Rate')
ax3.set_ylabel('True Positive Rate')
ax3.set_title('Receiver Operating Characteristic (Model 1)')
ax3.legend(loc="lower right")
st.pyplot(fig3)
